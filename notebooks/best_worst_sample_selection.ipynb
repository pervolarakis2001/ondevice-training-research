{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 22624,
     "sourceType": "modelInstanceVersion",
     "modelInstanceId": 18752
    }
   ],
   "dockerImageVersionId": 30698,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "# On-Device Training - Best/Worst Sample Selection\n# Import helper functions from our organized codebase\nimport sys\nimport os\n\n# Add the src directory to Python path for importing our modules\nsys.path.append('../src')\n\nfrom src.models import OnDeviceTrainingModel\nfrom src.data import DataPreprocessor\nfrom src.utils import SampleSelector, calculate_bvsb, save_images_to_zip\nfrom src.evaluation import plot_confidence_distribution\n\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt",
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2024-07-06T09:28:58.479829Z",
     "iopub.execute_input": "2024-07-06T09:28:58.480221Z",
     "iopub.status.idle": "2024-07-06T09:29:15.406742Z",
     "shell.execute_reply.started": "2024-07-06T09:28:58.480167Z",
     "shell.execute_reply": "2024-07-06T09:29:15.405609Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Load and prepare CIFAR-10 data using our DataPreprocessor\npreprocessor = DataPreprocessor(img_size=160, batch_size=128)\n\n# Prepare datasets with class splits (9 classes for N, 1 class for M)\ndatasets = preprocessor.prepare_datasets(n_classes=[0, 1, 2, 3, 4, 5, 6, 7, 8])\n\nprint(\"Available datasets:\", list(datasets.keys()))\nprint(\"Dataset shapes have been automatically handled by the preprocessor\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Load pre-trained model (you would update this path to your actual model)\n# model = tf.keras.models.load_model(\"path/to/your/model.keras\")\n\n# For demonstration, let's create a simple model\nmodel = OnDeviceTrainingModel(num_classes=10, img_size=160)\nprint(\"Model created successfully!\")\n\n# Initialize sample selector\nsample_selector = SampleSelector(model.model)\nprint(\"Sample selector initialized!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Select best and worst samples for each class\noutput_dir = './sample_outputs/'\nos.makedirs(output_dir, exist_ok=True)\n\n# Use the helper function to select samples for all classes\ntarget_classes = [0, 1, 2, 3, 4, 5, 6, 7, 8]  # N classes\nresults = sample_selector.select_all_classes(\n    datasets['train_n'], \n    target_classes, \n    n_samples=20,  # 20 best and worst samples per class\n    output_dir=output_dir\n)\n\nprint(\"Sample selection completed!\")\nfor class_idx, result in results.items():\n    print(f\"Class {class_idx}: {result['worst_samples']} worst, {result['best_samples']} best samples\")\n    print(f\"  Worst samples saved to: {result['worst_zip']}\")\n    print(f\"  Best samples saved to: {result['best_zip']}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "!pip install tensorflow pillow\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-06T09:44:19.579284Z",
     "iopub.execute_input": "2024-07-06T09:44:19.579694Z",
     "iopub.status.idle": "2024-07-06T09:44:36.659961Z",
     "shell.execute_reply.started": "2024-07-06T09:44:19.579663Z",
     "shell.execute_reply": "2024-07-06T09:44:36.658441Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (9.5.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.60.0)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\nCollecting keras<2.16,>=2.15.0 (from tensorflow)\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\nDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: keras 3.2.1\n    Uninstalling keras-3.2.1:\n      Successfully uninstalled keras-3.2.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.15.0\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "from tensorflow.keras.models import load_model\n\n# Load the model saved in Keras HDF5 format\nmodel = load_model(\"/kaggle/input/cifar9_95acc/tensorflow2/cifar9_95acc/1/mnv2_cifar9_160_fbn_4.keras\")\n\nNUM_CLASSES = 10\n(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n\n# create n- and m-datasets\ndef create_datasets(x, y, n_classes):\n\n    x_n = []\n    y_n = []\n    x_m = []\n    y_m = []\n    for x_, y_ in zip (x, y):\n        if y_ in n_classes:\n            x_n.append(x_)\n            y_n.append(y_)\n        else:\n            x_m.append(x_)\n            y_m.append(y_)\n    return np.array(x_n), np.array(y_n), np.array(x_m), np.array(y_m)\n    \nn_classes = [0, 1, 2, 3, 4, 5, 6, 7, 8]\nx_train_n, y_train_n, x_train_m, y_train_m = create_datasets(x_train, y_train, n_classes)\nx_test_n, y_test_n, x_test_m, y_test_m = create_datasets(x_test, y_test, n_classes)\n\ny_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\ny_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n\ny_train_n = tf.keras.utils.to_categorical(y_train_n, num_classes=10)\ny_test_n = tf.keras.utils.to_categorical(y_test_n, num_classes=10)\n\ny_train_m = tf.keras.utils.to_categorical(y_train_m, num_classes=10)\ny_test_m = tf.keras.utils.to_categorical(y_test_m, num_classes=10)\n\n# preprocessing\nIMAGE_SHAPE = (160, 160, 3)\n\npreprocessing = keras.Sequential(\n    [\n        layers.Rescaling(1./255.0, offset=0),\n        layers.Resizing(IMAGE_SHAPE[0], IMAGE_SHAPE[1], interpolation='bilinear')\n    ],\n    name=\"preprocessing\",\n)\n\ndata_augmentation = keras.Sequential(\n    [\n        layers.RandomFlip(\"horizontal\"),\n        layers.RandomRotation(factor=0.15),\n        layers.RandomContrast(factor=0.1),\n        layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n        layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n    ],\n    name=\"data_augmentation\",\n)\n\nIMG_SIZE = 160\nBATCH_SIZE = 128\nBUFFER_SIZE = BATCH_SIZE * 10\nAUTO = tf.data.AUTOTUNE\n\n# original\nds_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\nds_train = ds_train.shuffle(ds_train.cardinality()).batch(BATCH_SIZE).map(lambda x, y: (data_augmentation(preprocessing(x)), y)).prefetch(AUTO)\n\nds_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\nds_test = ds_test.batch(BATCH_SIZE).map(lambda x, y: (preprocessing(x), y)).prefetch(AUTO)\n\n# n-dataset\nds_train_n = tf.data.Dataset.from_tensor_slices((x_train_n, y_train_n))\nds_train_n = ds_train_n.shuffle(ds_train_n.cardinality()).batch(BATCH_SIZE).map(lambda x, y: (data_augmentation(preprocessing(x)), y)).prefetch(AUTO)\n\nds_test_n = tf.data.Dataset.from_tensor_slices((x_test_n, y_test_n))\nds_test_n = ds_test_n.batch(BATCH_SIZE).map(lambda x, y: (preprocessing(x), y)).prefetch(AUTO)\n\n# m-dataset\nds_train_m = tf.data.Dataset.from_tensor_slices((x_train_m, y_train_m))\nds_train_m = ds_train_m.shuffle(ds_train_m.cardinality()).batch(BATCH_SIZE).map(lambda x, y: (data_augmentation(preprocessing(x)), y)).prefetch(AUTO)\n\nds_test_m = tf.data.Dataset.from_tensor_slices((x_test_m, y_test_m))\nds_test_m = ds_test_m.batch(BATCH_SIZE).map(lambda x, y: (preprocessing(x), y)).prefetch(AUTO)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-06T09:32:14.856431Z",
     "iopub.execute_input": "2024-07-06T09:32:14.856842Z",
     "iopub.status.idle": "2024-07-06T09:32:40.824338Z",
     "shell.execute_reply.started": "2024-07-06T09:32:14.856809Z",
     "shell.execute_reply": "2024-07-06T09:32:40.822166Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:418: UserWarning: Skipping variable loading for optimizer 'adam', because it has 164 variables whereas the saved optimizer has 476 variables. \n  trackable.load_own_variables(weights_store.get(inner_path))\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 0us/step\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "ds_train_m = ds_train_m.unbatch().batch(1)\nds_train_n = ds_train_n.unbatch().batch(1)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-06T09:32:40.828845Z",
     "iopub.execute_input": "2024-07-06T09:32:40.829389Z",
     "iopub.status.idle": "2024-07-06T09:32:40.879496Z",
     "shell.execute_reply.started": "2024-07-06T09:32:40.829316Z",
     "shell.execute_reply": "2024-07-06T09:32:40.877946Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def calculate_bvsb(probs):\n    sorted_probs = np.sort(probs, axis=1)[:, ::-1]\n    bvsb = sorted_probs[:, 0] - sorted_probs[:, 1]\n    return bvsb\n\ndef save_images_to_zip(images, zip_path, image_format='JPEG'):\n    with zipfile.ZipFile(zip_path, 'w') as zipf:\n        for idx, image_tensor in enumerate(images):\n            # Convert TensorFlow tensor to NumPy array\n            image_array = image_tensor.numpy().astype('uint8')\n            \n            # Convert NumPy array to PIL Image\n            image_pil = Image.fromarray(image_array)\n            \n            # Save the PIL Image to a temporary file\n            temp_image_path = f'image_{idx}.{image_format.lower()}'\n            image_pil.save(temp_image_path, format=image_format)\n            \n            # Add the image to the zip file\n            zipf.write(temp_image_path, os.path.basename(temp_image_path))\n            \n            # Remove the temporary file\n            os.remove(temp_image_path)\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-06T10:08:33.059010Z",
     "iopub.execute_input": "2024-07-06T10:08:33.059560Z",
     "iopub.status.idle": "2024-07-06T10:08:33.069134Z",
     "shell.execute_reply.started": "2024-07-06T10:08:33.059518Z",
     "shell.execute_reply": "2024-07-06T10:08:33.068030Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\nimport os\nimport absl.logging\nfrom PIL import Image\nimport os\nimport zipfile\n# Initialize logging before any significant operations\nabsl.logging.set_verbosity(absl.logging.INFO)\nabsl.logging.use_absl_handler()\n# Define the directory to save outputs in Kaggle\noutput_dir = '/kaggle/working/'\nos.makedirs(output_dir, exist_ok=True)\n\nn_labels = [0,1,2,3, 4, 5, 6, 7,8]\n\nopt = keras.optimizers.Adam(learning_rate=0.000001, epsilon=0.002, amsgrad=True, weight_decay=1e-5)\nloss = keras.losses.CategoricalCrossentropy(label_smoothing=0.1)\nmodel.compile(optimizer=opt, loss=loss, metrics=[\"accuracy\"])\n\nbest_count = 0 \nfor i in n_labels:\n    \n\n    best_samples = []\n    worst_samples = [] \n    bsvb_data = []\n    count= 0\n    n_labels_copy = n_labels.copy()\n    n_labels_copy.remove(i)\n    n_labels_ = tf.keras.utils.to_categorical(n_labels_copy, num_classes=10)\n    for x, y in ds_train_n:\n        if  not any(np.array_equal(y[0].numpy(), n) for n in n_labels_):\n            prediction = model.predict(x,verbose=0)\n            if(np.argmax(y)==np.argmax(prediction)):\n                bvsb = calculate_bvsb(prediction)\n                bsvb_data.append((x.numpy().tolist(), y.numpy().tolist(), bvsb[0]))\n        \n    \n    sorted_bsvb_data = sorted(bsvb_data, key=lambda x: x[2])\n    x_y = [item[0] for item in sorted_bsvb_data]\n    worst = x_y[:50]\n    best = x_y[-50:]\n\n  \n    output_zip_path = f'/kaggle/working/images_{i}.zip'\n    save_images_to_zip(worst, output_zip_path, image_format='JPEG')\n    \n    ",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-06T10:23:43.470107Z",
     "iopub.execute_input": "2024-07-06T10:23:43.470712Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "for x,_ in ds_train_n:\n    print(x[0][0])\n    print(x)\n    break",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-05T20:22:13.350307Z",
     "iopub.execute_input": "2024-06-05T20:22:13.351124Z",
     "iopub.status.idle": "2024-06-05T20:22:16.168463Z",
     "shell.execute_reply.started": "2024-06-05T20:22:13.351087Z",
     "shell.execute_reply": "2024-06-05T20:22:16.167168Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": "tf.Tensor(\n[[0.22092624 0.2245467  0.22960743]\n [0.27307618 0.27605227 0.2818482 ]\n [0.32508153 0.32742912 0.3340498 ]\n [0.369316   0.37114206 0.37862673]\n [0.39494422 0.3964828  0.40478244]\n [0.39810482 0.39962596 0.40860102]\n [0.39989007 0.40140638 0.41102064]\n [0.4022001  0.40369022 0.41383538]\n [0.40493345 0.40637657 0.41693965]\n [0.40619096 0.407546   0.41817078]\n [0.39460206 0.39585945 0.40599236]\n [0.35526696 0.3563878  0.36540788]\n [0.30355173 0.30381417 0.3108064 ]\n [0.24937233 0.24810442 0.25284475]\n [0.19305035 0.1896677  0.19196136]\n [0.13566208 0.12956455 0.12919626]\n [0.08517879 0.07566963 0.07228711]\n [0.05562558 0.0419147  0.03498107]\n [0.05927802 0.04060604 0.02950482]\n [0.06821215 0.04424916 0.02892785]\n [0.07762614 0.04817171 0.02867757]\n [0.08721275 0.05216999 0.02855674]\n [0.09656693 0.05623604 0.02871513]\n [0.10436433 0.05950144 0.02866668]\n [0.10957858 0.06136088 0.02814972]\n [0.11296873 0.06281595 0.0281241 ]\n [0.11599881 0.06416867 0.02814169]\n [0.11871999 0.06541844 0.02815929]\n [0.12112905 0.0665641  0.02817514]\n [0.12297382 0.0674852  0.02813186]\n [0.12346081 0.06770147 0.02774742]\n [0.12185618 0.06665242 0.02664394]\n [0.11863877 0.06429922 0.0246603 ]\n [0.11424898 0.06085184 0.02189254]\n [0.10914428 0.0567218  0.0186375 ]\n [0.10428903 0.05279811 0.01557166]\n [0.1027178  0.05221685 0.01533724]\n [0.10850426 0.05913461 0.02140239]\n [0.12366799 0.07555009 0.03539551]\n [0.14145711 0.09461033 0.0516314 ]\n [0.16153245 0.11595679 0.06981058]\n [0.18355551 0.13925102 0.08964538]\n [0.20703594 0.16399078 0.11065315]\n [0.22928849 0.18743524 0.1302062 ]\n [0.2487309  0.20801297 0.14683044]\n [0.26664096 0.2271123  0.1619295 ]\n [0.28478703 0.24654022 0.17729542]\n [0.3025627  0.26563215 0.19243503]\n [0.3188582  0.28312895 0.2064487 ]\n [0.33633456 0.30132532 0.22181211]\n [0.3565034  0.32116586 0.2399827 ]\n [0.37809992 0.34132645 0.25967044]\n [0.39703417 0.35862342 0.27665406]\n [0.4120131  0.3719651  0.28968233]\n [0.4232022  0.38151687 0.2989207 ]\n [0.43083277 0.38755825 0.3045913 ]\n [0.4344638  0.3899349  0.30620834]\n [0.4332193  0.3879341  0.30292708]\n [0.4264877  0.38085514 0.29423568]\n [0.41485572 0.36893135 0.2808337 ]\n [0.3985222  0.35236362 0.26305217]\n [0.3797578  0.33343482 0.24325028]\n [0.3594951  0.31302676 0.22233295]\n [0.33788174 0.29131448 0.20076804]\n [0.31578857 0.26917732 0.17930648]\n [0.29469946 0.24807066 0.15892166]\n [0.27538383 0.22873744 0.14021184]\n [0.2581673  0.21150331 0.12348445]\n [0.2425605  0.19586445 0.10828383]\n [0.22747283 0.18062398 0.09363092]\n [0.21146722 0.16422026 0.0782466 ]\n [0.19488466 0.14704013 0.06247722]\n [0.18001536 0.13159487 0.04846954]\n [0.16798475 0.11908907 0.03744933]\n [0.15960452 0.11039587 0.03037302]\n [0.15396091 0.1045324  0.02620992]\n [0.15197062 0.10227825 0.02575242]\n [0.15255128 0.10251908 0.02778742]\n [0.1540752  0.10369107 0.0306562 ]\n [0.15582344 0.10518137 0.03374588]\n [0.15778679 0.10699435 0.03705069]\n [0.15994714 0.10911519 0.04056374]\n [0.16214402 0.11140189 0.04423492]\n [0.16424018 0.11376368 0.04815995]\n [0.16677693 0.11671695 0.05281755]\n [0.17149393 0.1219915  0.05978652]\n [0.18142936 0.13273779 0.07215689]\n [0.19862184 0.15112936 0.09203876]\n [0.22206233 0.17616044 0.11838519]\n [0.2509552  0.20694941 0.15052108]\n [0.28216028 0.24002796 0.18525901]\n [0.31383944 0.27341682 0.22058263]\n [0.34581253 0.30698884 0.25612292]\n [0.3779805  0.34065843 0.29176074]\n [0.4103819  0.37444478 0.32751536]\n [0.44274294 0.40815958 0.3631674 ]\n [0.47367847 0.44080555 0.39754236]\n [0.50297964 0.4722125  0.43046916]\n [0.5312498  0.502862   0.46254075]\n [0.5594146  0.5335349  0.49468267]\n [0.5879677  0.5646745  0.52740127]\n [0.61823803 0.597525   0.56206095]\n [0.65311974 0.6348264  0.601244  ]\n [0.69501764 0.6788827  0.6469102 ]\n [0.74022025 0.72609335 0.69551474]\n [0.784642   0.77250093 0.7432639 ]\n [0.8275055  0.81735027 0.7894547 ]\n [0.86868453 0.8605151  0.83396107]\n [0.90781134 0.90159875 0.8764417 ]\n [0.94341594 0.9389473  0.915587  ]\n [0.97541595 0.9723994  0.95130605]\n [1.0021422  1.0003084  0.9817159 ]\n [1.0221753  1.0213298  1.0051982 ]\n [1.0360343  1.0360526  1.0222765 ]\n [1.0410624  1.0418481  1.0301812 ]\n [1.0405294  1.0421629  1.0323825 ]\n [1.0375708  1.0403366  1.0323315 ]\n [1.0340521  1.0381032  1.031776  ]\n [1.0309885  1.0363635  1.0316167 ]\n [1.0287039  1.0354028  1.0321391 ]\n [1.0271997  1.0352215  1.0333439 ]\n [1.0266563  1.03597    1.0353769 ]\n [1.0272259  1.0375329  1.0382475 ]\n [1.0285829  1.0392027  1.0413811 ]\n [1.0302192  1.040492   1.0440336 ]\n [1.0318565  1.0412931  1.0459309 ]\n [1.0334938  1.041766   1.0472311 ]\n [1.0351311  1.0419316  1.0478752 ]\n [1.0366919  1.0420784  1.048209  ]\n [1.0377551  1.0425202  1.0485401 ]\n [1.0385392  1.0431254  1.048871  ]\n [1.0392812  1.0437858  1.049202  ]\n [1.0401154  1.0444478  1.0495329 ]\n [1.0410465  1.0451092  1.0498637 ]\n [1.0420786  1.0457667  1.0501926 ]\n [1.0432092  1.0463917  1.050505  ]\n [1.0444027  1.0469819  1.0508    ]\n [1.0453628  1.047456   1.0510371 ]\n [1.0460467  1.0478128  1.0512155 ]\n [1.046478   1.0480511  1.0513346 ]\n [1.0466032  1.0481243  1.0513712 ]\n [1.0466032  1.0481243  1.0513712 ]\n [1.0466032  1.0481243  1.0513712 ]\n [1.0466032  1.0481243  1.0513712 ]\n [1.0466032  1.0481243  1.0513712 ]\n [1.0466032  1.0481243  1.0513712 ]\n [1.0466017  1.0481232  1.0513706 ]\n [1.0465919  1.0481168  1.0513675 ]\n [1.0465295  1.0480752  1.0513467 ]\n [1.0464127  1.0479972  1.0513077 ]\n [1.0460899  1.0477822  1.0512002 ]\n [1.0456045  1.0474584  1.0510383 ]\n [1.0449274  1.0470071  1.0508126 ]\n [1.0440131  1.046397   1.0505079 ]\n [1.0430202  1.0457306  1.0501769 ]\n [1.0420272  1.0450096  1.049846  ]\n [1.0410343  1.0441036  1.0495149 ]\n [1.0400416  1.0430632  1.0491838 ]\n [1.0390486  1.0419147  1.0488529 ]\n [1.0380601  1.0406724  1.0485218 ]], shape=(160, 3), dtype=float32)\ntf.Tensor(\n[[[[0.22092624 0.2245467  0.22960743]\n   [0.27307618 0.27605227 0.2818482 ]\n   [0.32508153 0.32742912 0.3340498 ]\n   ...\n   [1.0400416  1.0430632  1.0491838 ]\n   [1.0390486  1.0419147  1.0488529 ]\n   [1.0380601  1.0406724  1.0485218 ]]\n\n  [[0.18400712 0.18806344 0.1941877 ]\n   [0.23729387 0.24070579 0.24766001]\n   [0.2915196  0.2942899  0.30216974]\n   ...\n   [1.0375051  1.0414131  1.0483323 ]\n   [1.0365822  1.0402172  1.0479803 ]\n   [1.0357684  1.0389982  1.0476122 ]]\n\n  [[0.14502397 0.14951614 0.15653192]\n   [0.19953871 0.20337102 0.2112877 ]\n   [0.25578442 0.2588706  0.26764327]\n   ...\n   [1.0352714  1.0400159  1.0473139 ]\n   [1.0347772  1.0390319  1.0468265 ]\n   [1.034687   1.0382202  1.0463238 ]]\n\n  ...\n\n  [[0.9840255  0.9850059  0.9878445 ]\n   [0.9962183  0.99713516 1.0002831 ]\n   [1.003583   1.0041049  1.0073279 ]\n   ...\n   [0.10209265 0.06538079 0.03957823]\n   [0.10178319 0.06506527 0.03874565]\n   [0.10123875 0.06452085 0.03778761]]\n\n  [[0.90704274 0.9074421  0.90986955]\n   [0.9365625  0.93684816 0.9396857 ]\n   [0.9631057  0.9630009  0.96606416]\n   ...\n   [0.10260174 0.06602404 0.04011581]\n   [0.10230563 0.0656509  0.0390568 ]\n   [0.10168749 0.06498324 0.03783346]]\n\n  [[0.80491227 0.80460733 0.8064922 ]\n   [0.83992153 0.83959705 0.84196305]\n   [0.8753341  0.87478113 0.8775176 ]\n   ...\n   [0.10140785 0.06536376 0.03951922]\n   [0.10161459 0.06533204 0.0384874 ]\n   [0.10155395 0.06505416 0.03737669]]]], shape=(1, 160, 160, 3), dtype=float32)\n",
     "output_type": "stream"
    }
   ]
  }
 ]
}