{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 22624,
     "sourceType": "modelInstanceVersion",
     "isSourceIdPinned": true,
     "modelInstanceId": 18752,
     "modelId": 28643
    }
   ],
   "dockerImageVersionId": 30746,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "# External Dataset Integration - Tiny ImageNet\n# Import our organized helper functions\nimport sys\nsys.path.append('../src')\n\nfrom src.data import DataPreprocessor\nfrom src.utils import setup_tiny_imagenet_experiment\nimport matplotlib.pyplot as plt",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-21T08:20:37.489573Z",
     "iopub.execute_input": "2024-08-21T08:20:37.489886Z",
     "iopub.status.idle": "2024-08-21T08:20:51.496973Z",
     "shell.execute_reply.started": "2024-08-21T08:20:37.489859Z",
     "shell.execute_reply": "2024-08-21T08:20:51.495781Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Setup Tiny ImageNet integration using our helper function\nclass_mappings = {\n    'n03706229': 8,  # magnetic compass -> class 8  \n    'n04456115': 9   # torch -> class 9\n}\n\n# This will download, extract, and prepare the external dataset\nimagenet_data = setup_tiny_imagenet_experiment(\n    output_dir='./',\n    class_mappings=class_mappings,\n    image_shape=(160, 160, 3)\n)\n\nprint(\"Tiny ImageNet integration completed!\")\nprint(\"Available data components:\", list(imagenet_data.keys()))\nprint(f\"Training samples: {len(imagenet_data['x_train_m'])}\")\nprint(f\"Test samples: {len(imagenet_data['x_test_m'])}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Visualize some samples from the external dataset\nfig, axes = plt.subplots(2, 5, figsize=(15, 6))\nfig.suptitle('Tiny ImageNet Samples for M-Dataset')\n\nfor i in range(10):\n    row = i // 5\n    col = i % 5\n    \n    # Get sample\n    sample_image = imagenet_data['x_train_m'][i]\n    sample_label = imagenet_data['y_train_m'][i]\n    \n    # Display\n    axes[row, col].imshow(sample_image.astype('uint8'))\n    axes[row, col].set_title(f'Class {np.argmax(sample_label)}')\n    axes[row, col].axis('off')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"External dataset samples visualized!\")\nprint(\"These images will serve as the M-dataset in on-device training experiments\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "#!pip install tensorflow pillow\n!pip install wget\n",
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2024-08-21T08:20:51.499076Z",
     "iopub.execute_input": "2024-08-21T08:20:51.499768Z",
     "iopub.status.idle": "2024-08-21T08:21:06.722024Z",
     "shell.execute_reply.started": "2024-08-21T08:20:51.499726Z",
     "shell.execute_reply": "2024-08-21T08:21:06.720617Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "from tensorflow.keras.models import load_model\n\n# Load the model saved in Keras HDF5 format\nmodel = load_model(\"/kaggle/input/cifar9_95acc/tensorflow2/cifar9_95acc/1/mnv2_cifar9_160_fbn_4.keras\")\n\nimport os, sys, wget\nfrom zipfile import ZipFile\n\nurl = 'http://cs231n.stanford.edu/tiny-imagenet-200.zip'\ntiny_imgdataset = wget.download(url, out=os.getcwd())\n\n# Extract the downloaded zip file\nzip_file = os.path.join(os.getcwd(), \"tiny-imagenet-200.zip\")\n\nif os.path.exists(zip_file):\n    with ZipFile(zip_file, 'r') as zip_ref:\n        zip_ref.extractall(os.getcwd())\n    print(\"Extraction completed.\")\nelse:\n    print(\"Zip file not found.\")",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-21T08:21:06.728275Z",
     "iopub.execute_input": "2024-08-21T08:21:06.728928Z",
     "iopub.status.idle": "2024-08-21T08:21:45.001272Z",
     "shell.execute_reply.started": "2024-08-21T08:21:06.728887Z",
     "shell.execute_reply": "2024-08-21T08:21:45.000235Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport os\nimport glob\n\n# Set parameters\nIMAGE_SHAPE = (160, 160, 3)\nIMG_SIZE = 160\nBATCH_SIZE = 128\nBUFFER_SIZE = BATCH_SIZE * 10\nAUTO = tf.data.AUTOTUNE\n\n# Define preprocessing layers\npreprocessing = keras.Sequential(\n    [\n        layers.Rescaling(1./255.0, offset=0),\n        layers.Resizing(IMAGE_SHAPE[0], IMAGE_SHAPE[1], interpolation='bilinear')\n    ],\n    name=\"preprocessing\",\n)\n\ndata_augmentation = keras.Sequential(\n    [\n        layers.RandomFlip(\"horizontal\"),\n        layers.RandomRotation(factor=0.15),\n        layers.RandomContrast(factor=0.1),\n        layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n        layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n    ],\n    name=\"data_augmentation\",\n)\ndef load_images_from_folder(folder, label):\n    image_files = glob.glob(os.path.join(folder, \"*.JPEG\"))\n    print(f\"Found {len(image_files)} images\")\n    images = []\n    labels = []\n    for img_file in image_files:\n        img = tf.io.read_file(img_file)\n        img = tf.image.decode_jpeg(img, channels=3)\n        img = tf.image.resize(img, [IMAGE_SHAPE[0], IMAGE_SHAPE[1]])  # Resize image\n        images.append(img)\n        labels.append(label)\n    return images, labels\n\n\n    \ntrain_folder = \"/kaggle/working/tiny-imagenet-200/train/n03706229/images\" #magnetic compass- πυξίδα\ntrain_images, train_labels = load_images_from_folder(train_folder, 9)\n\n\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-21T08:21:45.003348Z",
     "iopub.execute_input": "2024-08-21T08:21:45.004002Z",
     "iopub.status.idle": "2024-08-21T08:21:45.760944Z",
     "shell.execute_reply.started": "2024-08-21T08:21:45.003965Z",
     "shell.execute_reply": "2024-08-21T08:21:45.760169Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "import matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n\n# Assuming train_images is a list of TensorFlow tensors\n# Get the first image tensor from the list\nimg_tensor = train_images[3]\n\n# Convert the tensor to a numpy array and then to a PIL image\nimg_array = img_to_array(img_tensor)\nimg = array_to_img(img_array)\n\n# Plot the image\nplt.figure(figsize=(5, 5))\nplt.imshow(img)\nplt.axis('off')  # Hide axis labels\nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-21T08:21:45.761960Z",
     "iopub.execute_input": "2024-08-21T08:21:45.762210Z",
     "iopub.status.idle": "2024-08-21T08:21:46.007749Z",
     "shell.execute_reply.started": "2024-08-21T08:21:45.762187Z",
     "shell.execute_reply": "2024-08-21T08:21:46.006658Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "from tensorflow.keras.models import load_model\nfrom sklearn.model_selection import train_test_split\n# Load the model saved in Keras HDF5 format\nmodel = load_model(\"/kaggle/input/cifar9_95acc/tensorflow2/cifar9_95acc/1/mnv2_cifar9_160_fbn_4.keras\")\n\nNUM_CLASSES = 10\n(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n\n# create n- and m-datasets\ndef create_datasets(x, y, n_classes):\n\n    x_n = []\n    y_n = []\n    \n    for x_, y_ in zip (x, y):\n        if y_ in n_classes:\n            x_n.append(x_)\n            y_n.append(y_)\n    return np.array(x_n), np.array(y_n)\n    \nn_classes = [0, 1, 2, 3, 4, 5, 6, 7, 8]\nx_train_n, y_train_n= create_datasets(x_train, y_train, n_classes)\nx_test_n, y_test_n = create_datasets(x_test, y_test, n_classes)\n\n# Preprocess ImageNet samples\nx_m = []\ny_m = []\nfor m in  train_images:\n    x_m.append(m)\n    y_m.append(train_labels[0])\nx_m = np.array(x_m)\ny_m = np.array(y_m)\ntrain_ratio = 0.8\ntest_ratio = 0.2\n\n# Shuffle and split the data\nx_train_m, x_test_m, y_train_m, y_test_m = train_test_split(\n    x_m, y_m, \n    test_size=test_ratio, \n    random_state=42  # For reproducibility\n)\n\n\ny_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\ny_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n\ny_train_n = tf.keras.utils.to_categorical(y_train_n, num_classes=10)\ny_test_n = tf.keras.utils.to_categorical(y_test_n, num_classes=10)\n\ny_train_m = tf.keras.utils.to_categorical(y_train_m, num_classes=10)\ny_test_m = tf.keras.utils.to_categorical(y_test_m, num_classes=10)\n\n# preprocessing\nIMAGE_SHAPE = (160, 160, 3)\n\npreprocessing = keras.Sequential(\n    [\n        layers.Rescaling(1./255.0, offset=0),\n        layers.Resizing(IMAGE_SHAPE[0], IMAGE_SHAPE[1], interpolation='bilinear')\n    ],\n    name=\"preprocessing\",\n)\n\ndata_augmentation = keras.Sequential(\n    [\n        layers.RandomFlip(\"horizontal\"),\n        layers.RandomRotation(factor=0.15),\n        layers.RandomContrast(factor=0.1),\n        layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n        layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n    ],\n    name=\"data_augmentation\",\n)\n\nIMG_SIZE = 160\nBATCH_SIZE = 128\nBUFFER_SIZE = BATCH_SIZE * 10\nAUTO = tf.data.AUTOTUNE\n\n# original\nds_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\nds_train = ds_train.shuffle(ds_train.cardinality()).batch(BATCH_SIZE).map(lambda x, y: (data_augmentation(preprocessing(x)), y)).prefetch(AUTO)\n\nds_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\nds_test = ds_test.batch(BATCH_SIZE).map(lambda x, y: (preprocessing(x), y)).prefetch(AUTO)\n\n# n-dataset\nds_train_n = tf.data.Dataset.from_tensor_slices((x_train_n, y_train_n))\nds_train_n = ds_train_n.shuffle(ds_train_n.cardinality()).batch(BATCH_SIZE).map(lambda x, y: (data_augmentation(preprocessing(x)), y)).prefetch(AUTO)\n\nds_test_n = tf.data.Dataset.from_tensor_slices((x_test_n, y_test_n))\nds_test_n = ds_test_n.batch(BATCH_SIZE).map(lambda x, y: (preprocessing(x), y)).prefetch(AUTO)\n\n# m-dataset\nds_train_m = tf.data.Dataset.from_tensor_slices((x_train_m, y_train_m))\nds_train_m = ds_train_m.shuffle(ds_train_m.cardinality()).batch(BATCH_SIZE).map(lambda x, y: (data_augmentation(preprocessing(x)), y)).prefetch(AUTO)\n\nds_test_m = tf.data.Dataset.from_tensor_slices((x_test_m, y_test_m))\nds_test_m = ds_test_m.batch(BATCH_SIZE).map(lambda x, y: (preprocessing(x), y)).prefetch(AUTO)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-21T08:21:46.010249Z",
     "iopub.execute_input": "2024-08-21T08:21:46.010612Z",
     "iopub.status.idle": "2024-08-21T08:22:12.669069Z",
     "shell.execute_reply.started": "2024-08-21T08:21:46.010579Z",
     "shell.execute_reply": "2024-08-21T08:22:12.668262Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "ds_test_n = ds_test_n.unbatch().batch(1)\nds_train_n = ds_train_n.unbatch().batch(1)\nds_train_m = ds_train_m.unbatch().batch(1)\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-21T08:22:12.670146Z",
     "iopub.execute_input": "2024-08-21T08:22:12.670446Z",
     "iopub.status.idle": "2024-08-21T08:22:12.703205Z",
     "shell.execute_reply.started": "2024-08-21T08:22:12.670420Z",
     "shell.execute_reply": "2024-08-21T08:22:12.702359Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "num_batches = sum(1 for _ in ds_train_m)\nprint(\"Number of batches in ds_test_m:\", num_batches)\n\n# Calculate the total number of examples\n# Iterate through the dataset and count the total number of examples\ntotal_examples = sum(len(batch[0]) for batch in ds_train_m)\nprint(\"Total number of examples in ds_test_m:\", total_examples)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-16T12:24:57.371154Z",
     "iopub.execute_input": "2024-08-16T12:24:57.371563Z",
     "iopub.status.idle": "2024-08-16T12:25:06.137243Z",
     "shell.execute_reply.started": "2024-08-16T12:24:57.371533Z",
     "shell.execute_reply": "2024-08-16T12:25:06.136027Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "def calculate_bvsb(probs):\n    sorted_probs = np.sort(probs, axis=1)[:, ::-1]\n    bvsb = sorted_probs[:, 0] - sorted_probs[:, 1]\n    return bvsb\n\ndef save_images(images, output_dir, image_format='PNG'):\n    os.makedirs(output_dir, exist_ok=True)\n    \n    for idx, image in enumerate(images):\n        image = np.clip(image, 0.0, 1.0)\n        image_uint8 = (image.squeeze() * 255.0).astype(np.uint8)\n        if image_uint8.shape[0] == 3:\n            image_uint8 = np.transpose(image_uint8, (1, 2, 0))\n        image_pil = Image.fromarray(image_uint8)\n        temp_image_path = os.path.join(output_dir, f'image_{idx}.{image_format.lower()}')\n        image_pil.save(temp_image_path, format=image_format)\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-21T08:25:29.205875Z",
     "iopub.execute_input": "2024-08-21T08:25:29.206812Z",
     "iopub.status.idle": "2024-08-21T08:25:29.214561Z",
     "shell.execute_reply.started": "2024-08-21T08:25:29.206778Z",
     "shell.execute_reply": "2024-08-21T08:25:29.213513Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\nimport os\nimport absl.logging\nfrom PIL import Image\nimport os\nimport zipfile\nm_samples = []\ni =0 \nfor x, y in ds_train_m:\n    m_samples.append(x.numpy())\n    if i == 50:\n        break\n    i+=1 \n\noutput_zip_path = '/kaggle/working/m_samples_imagenet'\nsave_images(m_samples, output_zip_path, image_format='PNG')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-21T08:26:54.935536Z",
     "iopub.execute_input": "2024-08-21T08:26:54.936414Z",
     "iopub.status.idle": "2024-08-21T08:26:57.880287Z",
     "shell.execute_reply.started": "2024-08-21T08:26:54.936381Z",
     "shell.execute_reply": "2024-08-21T08:26:57.879275Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "import shutil\nimport os\n\n# Specify the directory you want to zip (for example, 'my_directory')\ndir_to_zip = \"/kaggle/working/m_samples_imagenet\"\n\n# Output zip file path\noutput_zip = \"/kaggle/working/m_samples_imagenet.zip\"\n\n# Create a zip file of the directory\nshutil.make_archive(output_zip.replace(\".zip\", \"\"), 'zip', dir_to_zip)\n\nfrom IPython.display import FileLink\n\n# Provide a download link for the zip file\nFileLink(output_zip)\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-21T08:45:56.889646Z",
     "iopub.execute_input": "2024-08-21T08:45:56.890567Z",
     "iopub.status.idle": "2024-08-21T08:45:56.967906Z",
     "shell.execute_reply.started": "2024-08-21T08:45:56.890532Z",
     "shell.execute_reply": "2024-08-21T08:45:56.967062Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "execution_count": 11,
     "output_type": "execute_result",
     "data": {
      "text/plain": "/kaggle/working/m_samples_imagenet.zip",
      "text/html": "<a href='/kaggle/working/m_samples_imagenet.zip' target='_blank'>/kaggle/working/m_samples_imagenet.zip</a><br>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": "from sklearn.model_selection import train_test_split\nn_labels = [0,1,2,3, 4, 5, 6, 7,8]\nx_test = []\ny_test = []\nlabels = []\nfor x,y in ds_test_n:  \n    x_test.append(x.numpy())\n    y_test.append(np.argmax(y))\n  \nx_test = np.array(x_test,dtype=np.float32)\ny_test = np.array(y_test,dtype=np.float32)\ntest_size = 270\nrandom_seed = 42  \n_,x_sampled,_, y_sampled = train_test_split(\n    x_test, y_test,test_size = test_size , stratify=y_test, random_state=random_seed\n)\n\ny=  tf.keras.utils.to_categorical(y_sampled, num_classes=10)\n\nds_test_sampled = tf.data.Dataset.from_tensor_slices((x_sampled, y))\ndef reshape_y(x, y):\n    y = tf.reshape(y, (1, 10))\n    return x, y\nds_test_stratified = ds_test_sampled.map(reshape_y)\nfor i in n_labels:\n    arr = []\n    count = 0 \n    n_labels_copy = n_labels.copy()\n    n_labels_copy.remove(i)\n    n_labels_ = tf.keras.utils.to_categorical(n_labels_copy, num_classes=10)\n    for x,y in ds_test_stratified:\n        if  not any(np.array_equal(y[0].numpy(), n) for n in n_labels_):\n            count+=1\n            arr.append(x.numpy())\n    #output_zip_path =f'/kaggle/working/ds_test_strartified_{i}'\n   # save_images(arr, output_zip_path, image_format='PNG')\n    print(\"samples of class {} = {}\".format(i,count))\n            \n    \n_, acc_sampled = model.evaluate( ds_test_stratified, verbose=0)\nacc_sampled\n\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "from sklearn.model_selection import train_test_split\nimport random\nfrom collections import Counter\nfrom sklearn.utils import resample\n\n\nn_labels = [0,1,2,3, 4, 5, 6, 7,8]\naccuracies_sampled = []\nsampled_datasets = []\ndef reshape_y(x, y):\n    y = tf.reshape(y, (1, 10))\n    return x, y\n\nfor i in n_labels:\n    n_labels_copy = n_labels.copy()\n    n_labels_copy.remove(i)\n    n_labels_ = tf.keras.utils.to_categorical(n_labels_copy, num_classes=10)\n    samples_true = []\n    samples_false = []\n    x_t = []\n    y_t = []\n    #find the images that model classifies correct and false \n    for x,y in ds_test_n:\n        if  not any(np.array_equal(y[0].numpy(), n) for n in n_labels_):\n            x_t.append(x.numpy())\n            y_t.append(y)\n            prediction = model.predict(x,verbose=0).astype(np.float64)\n            if(np.argmax(y)==np.argmax(prediction)):\n                samples_true.append((x,np.max(prediction))) # save top-1 softmax\n            else:\n                samples_false.append((x,prediction))\n    \n    # plot histogram of top-1 softmax \n\n    top_1 = [top_1 for _,top_1 in samples_true]\n    \"\"\" \n    plt.hist(top_1,bins=20,edgecolor='black')\n    plt.title(f'Top-1 softmax Histogram for class {i}')\n    plt.xlabel('Value')\n    plt.ylabel('Frequency')\n    plt.savefig(f'top_1_hist_class_{i}.png')\n    plt.show()\n    \"\"\"\n    num_samples = 29  # Number of samples to keep\n    bins = np.histogram_bin_edges(top_1, bins=20)  # Define bin edges\n    bin_indices = np.digitize(top_1, bins)  # Assign scores to bins\n\n    sub_samples = []\n\n    for b in range(1, len(bins)):\n        bin_samples = [(x, score) for (x, score), bin_idx in zip(samples_true, bin_indices) if bin_idx == b]\n        if bin_samples:\n            # Subsample from the bin to keep the same distribution\n            subsampled_bin_samples = resample(bin_samples, replace=False, n_samples=int(np.round(len(bin_samples) * num_samples / len(top_1))))\n            sub_samples.extend(subsampled_bin_samples)\n            \n    if len( sub_samples) > num_samples:\n        sub_samples = resample(sub_samples, replace=False, n_samples=num_samples)\n    elif len(sub_samples) < num_samples:\n        additional_samples = resample(samples_true, replace=False, n_samples=num_samples - len(sub_samples))\n        sub_samples.extend(additional_samples)\n\n    # Now `stratified_samples` contains the subsampled data maintaining the original distribution\n    sub_top_1 = [sub_top_1 for _,sub_top_1 in sub_samples]\n   \n    print(len(sub_top_1))\n    \"\"\" \n    plt.hist(sub_top_1,edgecolor='black')\n    plt.title(f'Top-1 softmax Histogram for class {i} and subsamples')\n    plt.xlabel('Value')\n    plt.ylabel('Frequency')\n    plt.savefig(f'sub_top_1_hist_class_{i}.png')\n    plt.show()\n    \"\"\"\n    label_1 = []\n    for j in range(29):\n        label_1.append(i)\n    y=  tf.keras.utils.to_categorical(label_1, num_classes=10)\n    ds_true= tf.data.Dataset.from_tensor_slices(([x.numpy() for x,_ in sub_samples], y))\n    new_ds_true = ds_true.map(reshape_y)\n    \n    # find 1 image from samples_false\n    pred_labels_false = [np.argmax(sample[1]) for sample in samples_false]\n    counter = Counter(pred_labels_false)\n    common_label, common_count = counter.most_common(1)[0]\n    print(f\"for class{i} most common misclassified class= {common_label},count={common_count}\")\n    list_false=[]\n    for sample in samples_false:\n        if np.argmax(sample[1]) == common_label:\n            list_false.append(sample)\n            break \n    \n    label_2 = tf.keras.utils.to_categorical(i, num_classes=10)\n    a = []\n    a.append(label_2)\n    image = [sample[0] for sample in list_false]\n    ds_false = tf.data.Dataset.from_tensor_slices((image,a)) \n    new_ds_false =  ds_false.map(reshape_y) \n    \n    sampled_test = new_ds_true.concatenate(new_ds_false)\n    arr = []\n    \n    for x,_ in sampled_test:\n        arr.append(x.numpy())\n    output_zip_path = f'/kaggle/working/ds_test_subsampled_{i}'\n    save_images(arr, output_zip_path, image_format='PNG')\n   \n\n    sampled_datasets.append(sampled_test)\n        \nds_test_sampled = sampled_datasets[0]\nfor ds in sampled_datasets[1:]:\n    ds_test_sampled = ds_test_sampled.concatenate(ds) \n    \n\n    \n    \n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "import tensorflow as tf\nimport numpy as np\nimport random\n\nclasses = [0,1,2,3,4,5,6,7,8]\n\ndef get_unique_images(classes,dataset):\n    labels = tf.keras.utils.to_categorical(classes, num_classes=10)\n    images_labels = []\n    for x, y in dataset:\n        if y in labels and not any(np.array_equal(y.numpy(), item[1].numpy()) for item in images_labels): \n            images_labels.append((x, y))\n        if len([item[1] for item in images_labels]) == len(classes):\n            break\n    \n    return images_labels\n    ",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "classes = [0,1,2,3,4,5,6,7,8]\n\ndef take_samples(num, dataset):\n    labels = tf.keras.utils.to_categorical(classes, num_classes=10)\n    images_labels = []\n    samples_per_class = {cls: 0 for cls in classes}\n    for x, y in dataset:\n        if y in labels and samples_per_class[np.argmax(y)] < num:\n            images_labels.append((x, y))\n            samples_per_class[np.argmax(y)] += 1\n        if all(count == num for count in samples_per_class.values()):\n              break\n    \n    return images_labels",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "class PrintLossCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        print(f\"Epoch {epoch+1}: loss = {logs['loss']}, accuracy = {logs['accuracy']}\")\n    \n    def on_batch_end(self, batch, logs=None):\n        print(f\"Batch {batch+1}: loss = {logs['loss']}\")",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "import time\nTime = []\ndef AllTests(): \n    model = load_model(\"/kaggle/input/cifar9_95acc/tensorflow2/cifar9_95acc/1/mnv2_cifar9_160_fbn_4.keras\")\n    opt = keras.optimizers.Adam(learning_rate=0.000005, epsilon=0.002, amsgrad=True, weight_decay=1e-5)\n    loss = keras.losses.CategoricalCrossentropy(label_smoothing=0.1)\n    model.compile(optimizer=opt, loss=loss, metrics=[\"accuracy\"])\n    loss_n=[]\n    acc_n = []\n    acc_nm = []\n    acc_n_stratified = []\n    acc_n_subsampling = []\n    acc_m = []\n    loss_nm = []\n    loss_n_stratified = []\n    loss_n_subsampling = []\n    loss_m = []\n    counter = 1e10\n    i = 0\n    c = 0 # for counting the total number of training steps\n    case = True\n    a = 0 \n    dataset_n = take_samples(5, ds_train_n)\n    m_dict = {}\n    var = False \n    while(case):\n        \n        print(i+1)\n        m_data = ds_train_m.take(1)\n        \n        if m_data not in list(m_dict.keys()):\n            \n            ds_n = random.sample(dataset_n, 4)\n            x_n = [item[0] for item in ds_n]\n            y_n = [item[1] for item in ds_n]\n            ds_n = tf.data.Dataset.from_tensor_slices((x_n,y_n))\n            ds = m_data.concatenate(ds_n)\n            \n            start_time = time.time()\n            history = model.fit(ds, epochs=1, verbose=0)\n            end_time = time.time()\n            elapsed_time = end_time - start_time\n            Time.append(elapsed_time)\n            c += 1\n            \n            k = random.randint(5, 10)\n            m_dict[m_data] = i+k # next i that this image needs to be used again\n\n            loss, accuracy_n = model.evaluate(ds_test_n, verbose=0)\n            print(\"Test accuracy on n: {}%\".format(round(accuracy_n*100, 2)))\n            acc_n.append(accuracy_n)\n            loss_n.append(loss)\n            \n            # Stratified Sampling \n            loss_n_str, accuracy_n_stratified = model.evaluate(ds_test_stratified, verbose=0)\n            print(\"Test accuracy on n for stratified Sampling: {}%\".format(round(accuracy_n_stratified*100, 2)))\n            acc_n_stratified.append(accuracy_n_stratified)\n            loss_n_stratified.append(loss_n_str)\n            \n             # Subsampling \n            loss_n_Sub , accuracy_n_sub = model.evaluate(ds_test_sampled, verbose=0)\n            print(\"Test accuracy on n for subsampling: {}%\".format(round(accuracy_n_sub*100, 2)))\n            acc_n_subsampling.append(accuracy_n_sub)\n            loss_n_subsampling.append(loss_n_Sub)\n\n            loss_m_, accuracy_m = model.evaluate(ds_test_m, verbose=0)\n            print(\"Test accuracy on m: {}%\".format(round(accuracy_m*100, 2)))\n            acc_m.append(accuracy_m)\n            loss_m.append(loss_m_)\n            \n            # check ending condition\n            if abs(accuracy_n - accuracy_m) <= 0.02:\n                print(\"For Original Test set, the accuracies were equal in iteration {} with total training steps={}, accuracy={}, and m_samples={}\".format(i+1, c,accuracy_n, len(m_dict.keys())))\n                if not var:\n                    counter =  i + 5\n                var = True  \n            if abs(accuracy_n_stratified - accuracy_m) <= 0.02:\n                print(\"For Stratified sampling, the accuracies were equal in iteration {} with total training steps={}, accuracy={}, and m_samples={}\".format(i+1, c, accuracy_m, len(m_dict.keys())))\n                if not var:\n                    counter =  i + 5\n                var = True \n            if abs(accuracy_n_sub - accuracy_m) <= 0.02:\n                print(\"For Subsampling, the accuracies were equal in iteration {} with total training steps={}, accuracy={}, and m_samples={}\".format(i+1, c, accuracy_m, len(m_dict.keys())))\n                if not var:\n                    counter =  i + 5\n                var = True \n            # check stored images from m\n            for m_data, next_i in m_dict.items():       \n                if next_i == i:\n                    \n                    # update i\n                    k = random.randint(5, 10)\n                    m_dict[m_data] += k # next i that this image needs to be used again\n                    \n                    # generate a new 4-sample dataset from n-dataset again\n                    ds_n = random.sample(dataset_n, 4)\n                    x_n = [item[0] for item in ds_n]\n                    y_n = [item[1] for item in ds_n]\n                    ds_n = tf.data.Dataset.from_tensor_slices((x_n,y_n))\n                    ds_new = m_data.concatenate(ds_n)\n                    \n                    # fit\n                    start_time = time.time()\n                    history = model.fit(ds_new, epochs=1, verbose=0)\n                    end_time = time.time()\n                    elapsed_time = end_time - start_time\n                    Time.append(elapsed_time)\n                    c += 1\n                    \n                    loss, accuracy_n = model.evaluate(ds_test_n, verbose=0)\n                    print(\"Test accuracy on n: {}%\".format(round(accuracy_n*100, 2)))\n                    acc_n.append(accuracy_n)\n                    loss_n.append(loss)\n                    \n                     # Stratified Sampling \n                    loss_n_str, accuracy_n_stratified = model.evaluate(ds_test_stratified, verbose=0)\n                    print(\"Test accuracy on n for stratified Sampling: {}%\".format(round(accuracy_n_stratified*100, 2)))\n                    acc_n_stratified.append(accuracy_n_stratified)\n                    loss_n_stratified.append(loss_n_str)\n                    \n                    # Subsampling \n                    loss_n_Sub , accuracy_n_sub = model.evaluate(ds_test_sampled, verbose=0)\n                    print(\"Test accuracy on n for subsampling: {}%\".format(round(accuracy_n_sub*100, 2)))\n                    acc_n_subsampling.append(accuracy_n_sub)\n                    loss_n_subsampling.append(loss_n_Sub)\n\n                    loss_m_, accuracy_m = model.evaluate(ds_test_m, verbose=0)\n                    print(\"Test accuracy on m: {}%\".format(round(accuracy_m*100, 2)))\n                    acc_m.append(accuracy_m)\n                    loss_m.append(loss_m_)\n\n                    if abs(accuracy_n - accuracy_m) <= 0.02:\n                        print(\"For Original Test set, the accuracies were equal in iteration {} with total training steps={}, accuracy={}, and m_samples={}\".format(i+1, c,accuracy_n, len(m_dict.keys())))\n                        if not var:\n                            counter = i + 5\n                        var = True \n                    if abs(accuracy_n_stratified - accuracy_m) <= 0.02:\n                        print(\"For Stratified sampling, the accuracies were equal in iteration {} with total training steps={}, accuracy={}, and m_samples={}\".format(i+1, c, accuracy_m, len(m_dict.keys())))\n                        if not var:\n                            counter = i + 5\n                        var = True \n                    if abs(accuracy_n_sub - accuracy_m) <= 0.02:\n                        print(\"For Subsampling, the accuracies were equal in iteration {} with total training steps={}, accuracy={}, and m_samples={}\".format(i+1, c, accuracy_m, len(m_dict.keys())))\n                        if not var:\n                            counter =  i + 5\n                        var = True \n                    \n        if i >= counter:  \n            break\n        i+=1\n        print()\n    return acc_n, acc_n_stratified, acc_n_subsampling, acc_m,loss_n, loss_n_stratified, loss_n_subsampling,loss_m,Time",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "acc_n, acc_n_stratified, acc_n_subsampling, acc_m,loss_n, loss_n_stratified, loss_n_subsampling,loss_m,Time = AllTests()\nplt.plot(acc_n, label=\"Original 9 classes\")\nplt.plot(acc_n_stratified, label=\"Stratified Sampling in 9 classes\")\nplt.plot(acc_n_subsampling, label=\"Stratified Sampling in 9 classes\")\nplt.plot(acc_m, label=\"1 class on Server\")\nplt.xlabel(\"Training Steps\")  \nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.savefig('comparison_acc_all.png')\nplt.show()\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "del Time[0]\nplt.plot(Time ,label='Training Time on Server')\n#plt.plot(device_time ,label='Training Time on Device')\nplt.xlabel(\"Traininng Steps\")  \nplt.ylabel(\"Time\")\nplt.legend()\nplt.savefig('Time_all.png')\nplt.show()\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  }
 ]
}