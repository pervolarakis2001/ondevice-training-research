{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RsKLdQshg0CT"
   },
   "source": [
    "# TensorFlow Lite Model Conversion for On-Device Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from src.models import OnDeviceTrainingModel\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create on-device training model using our class\n",
    "model = OnDeviceTrainingModel(num_classes=10, img_size=160, learning_rate=1.4e-5)\n",
    "\n",
    "# Load pre-trained weights if available\n",
    "# model.model.load_weights(\"/path/to/your/weights.h5\")\n",
    "\n",
    "print(\"On-device training model created successfully!\")\n",
    "print(f\"Model input shape: {model.model.input_shape}\")\n",
    "print(f\"Model output shape: {model.model.output_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to TensorFlow Lite using our built-in method\n",
    "saved_model_dir = \"on_device_training_model\"\n",
    "tflite_model = model.convert_to_tflite(saved_model_dir)\n",
    "\n",
    "# Save the TFLite model\n",
    "tflite_filename = 'on_device_training_model.tflite'\n",
    "with open(tflite_filename, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"Model successfully converted to TensorFlow Lite!\")\n",
    "print(f\"Saved as: {tflite_filename}\")\n",
    "print(f\"Model size: {len(tflite_model) / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_filename)\n",
    "\n",
    "# Get model signatures\n",
    "signatures = interpreter.get_signature_list()\n",
    "print('Available signatures:', list(signatures.keys()))\n",
    "\n",
    "# Test inference signature\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(f\"\\nInference input shape: {input_details[0]['shape']}\")\n",
    "print(f\"Inference output shape: {output_details[0]['shape']}\")\n",
    "\n",
    "# Create dummy input for testing\n",
    "test_input = np.random.random((1, 160, 160, 3)).astype(np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], test_input)\n",
    "interpreter.invoke()\n",
    "output = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "print(f\"Test inference successful! Output shape: {output.shape}\")\n",
    "print(\"Model is ready for on-device deployment!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IngMRZrBgvuT"
   },
   "outputs": [],
   "source": [
    "\n",
    "pip install tensorflow==2.15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zktbVSbMvBUs"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "#import tensorflow as tf  # For tf.data\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.applications import EfficientNetB0\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-14T13:28:44.891221Z",
     "iopub.status.busy": "2024-04-14T13:28:44.890211Z",
     "iopub.status.idle": "2024-04-14T13:28:44.897727Z",
     "shell.execute_reply": "2024-04-14T13:28:44.895822Z",
     "shell.execute_reply.started": "2024-04-14T13:28:44.891184Z"
    },
    "id": "ETvSbjQi0Lng",
    "outputId": "2f22b2d0-f5fa-4a65-9f95-1f5443273d18",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.15.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t72oHLsObzow",
    "outputId": "e5653446-405d-4c73-a6e2-510e1870be14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQdqtCGT0Lnh"
   },
   "source": [
    "Load model trained on server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i_YwTf3ecggZ"
   },
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (160, 160, 3)\n",
    "IMG_SIZE = 160\n",
    "def build_model(num_classes):\n",
    "\n",
    "    base_model = tf.keras.applications.MobileNetV2(input_shape=IMAGE_SHAPE, include_top=False, alpha=1.0)\n",
    "\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Rebuild top\n",
    "    x = base_model.output\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
    "\n",
    "    top_dropout_rate = 0.1\n",
    "    x = tf.keras.layers.Dropout(top_dropout_rate, name=\"top_dropout1\")(x)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "    model = tf.keras.Model(base_model.input, outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T13:29:33.373002Z",
     "iopub.status.busy": "2024-04-14T13:29:33.372603Z",
     "iopub.status.idle": "2024-04-14T13:29:35.170679Z",
     "shell.execute_reply": "2024-04-14T13:29:35.168576Z",
     "shell.execute_reply.started": "2024-04-14T13:29:33.372974Z"
    },
    "id": "6taUVyWd0Lnk",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Model(tf.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "\n",
    "    self.model = build_model(num_classes=10)\n",
    "    self.model.trainable = True\n",
    "    for layer in self.model.layers:\n",
    "      if isinstance(layer, layers.BatchNormalization):\n",
    "          layer.trainable = False\n",
    "    self.opt = tf.keras.optimizers.Adam(learning_rate=1.4e-5, epsilon=0.002, amsgrad=True, weight_decay=1e-5)\n",
    "    self.Loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1)\n",
    "    self.model.compile(optimizer=self.opt, loss=self.Loss, metrics=[\"accuracy\"])\n",
    "\n",
    "  # The `train` function takes a batch of input images and labels.\n",
    "  @tf.function(input_signature=[\n",
    "      tf.TensorSpec([5, IMG_SIZE, IMG_SIZE, 3], tf.float32),\n",
    "      tf.TensorSpec([5, 10], tf.float32),\n",
    "  ])\n",
    "  def train(self, x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "      prediction = self.model(x,training=True)  # next approach remove the training=true\n",
    "      loss = self.model.loss(y, prediction)\n",
    "    gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "    self.model.optimizer.apply_gradients(\n",
    "        zip(gradients, self.model.trainable_variables))\n",
    "\n",
    "    result = {\"loss\": loss}\n",
    "    return result\n",
    "\n",
    "  @tf.function(input_signature=[\n",
    "      tf.TensorSpec([None, IMG_SIZE, IMG_SIZE, 3], tf.float32),\n",
    "  ])\n",
    "  def infer(self, x):\n",
    "    probabilities = self.model(x)\n",
    "    return {\"output\": probabilities}\n",
    "\n",
    "  @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])\n",
    "  def save(self, checkpoint_path):\n",
    "    tensor_names = [weight.name for weight in self.model.weights]\n",
    "    tensors_to_save = [weight.read_value() for weight in self.model.weights]\n",
    "    tf.raw_ops.Save(\n",
    "        filename=checkpoint_path, tensor_names=tensor_names,\n",
    "        data=tensors_to_save, name='save')\n",
    "    return {\n",
    "        \"checkpoint_path\": checkpoint_path\n",
    "    }\n",
    "\n",
    "  @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])\n",
    "  def restore(self, checkpoint_path):\n",
    "    restored_tensors = {}\n",
    "    for var in self.model.weights:\n",
    "      restored = tf.raw_ops.Restore(\n",
    "          file_pattern=checkpoint_path, tensor_name=var.name, dt=var.dtype,\n",
    "          name='restore')\n",
    "      var.assign(restored)\n",
    "      restored_tensors[var.name] = restored\n",
    "    return restored_tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1sboYEH7dGil",
    "outputId": "1cad7344-cae2-4bdc-db88-5df6232870de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5\n",
      "9406464/9406464 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 1 variables whereas the saved optimizer has 164 variables. \n",
      "WARNING:absl:Importing a function (__inference_internal_grad_fn_40240) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_internal_grad_fn_40567) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    }
   ],
   "source": [
    "m = Model()\n",
    "m.model.load_weights(\"/content/drive/MyDrive/Diploma thesis/mnv2_cifar8_160.weights.h5\")  # I CHANGED FOR 8-2 SPLIT !!!!\n",
    "\n",
    "\n",
    "\n",
    "SAVED_MODEL_DIR = \"the_saved_model\"\n",
    "tf.saved_model.save(\n",
    "    m,\n",
    "    SAVED_MODEL_DIR,\n",
    "    signatures={\n",
    "        'train':\n",
    "            m.train.get_concrete_function(),\n",
    "        'infer':\n",
    "            m.infer.get_concrete_function(),\n",
    "        'save':\n",
    "            m.save.get_concrete_function(),\n",
    "        'restore':\n",
    "            m.restore.get_concrete_function(),\n",
    "    })\n",
    "\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL_DIR)\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS  # enable TensorFlow ops.\n",
    "]\n",
    "\n",
    "converter.experimental_enable_resource_variables = True\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model\n",
    "with open('lr_014_model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-S4zTE7lsjOl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tZfOJ7zJN8iA",
    "outputId": "5356cab2-38a2-45e7-e8dd-9dba66d0688f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signature: {'infer': {'inputs': ['x'], 'outputs': ['output']}, 'restore': {'inputs': ['checkpoint_path'], 'outputs': ['Conv1/kernel:0', 'Conv_1/kernel:0', 'Conv_1_bn/beta:0', 'Conv_1_bn/gamma:0', 'Conv_1_bn/moving_mean:0', 'Conv_1_bn/moving_variance:0', 'block_10_depthwise/depthwise_kernel:0', 'block_10_depthwise_BN/beta:0', 'block_10_depthwise_BN/gamma:0', 'block_10_depthwise_BN/moving_mean:0', 'block_10_depthwise_BN/moving_variance:0', 'block_10_expand/kernel:0', 'block_10_expand_BN/beta:0', 'block_10_expand_BN/gamma:0', 'block_10_expand_BN/moving_mean:0', 'block_10_expand_BN/moving_variance:0', 'block_10_project/kernel:0', 'block_10_project_BN/beta:0', 'block_10_project_BN/gamma:0', 'block_10_project_BN/moving_mean:0', 'block_10_project_BN/moving_variance:0', 'block_11_depthwise/depthwise_kernel:0', 'block_11_depthwise_BN/beta:0', 'block_11_depthwise_BN/gamma:0', 'block_11_depthwise_BN/moving_mean:0', 'block_11_depthwise_BN/moving_variance:0', 'block_11_expand/kernel:0', 'block_11_expand_BN/beta:0', 'block_11_expand_BN/gamma:0', 'block_11_expand_BN/moving_mean:0', 'block_11_expand_BN/moving_variance:0', 'block_11_project/kernel:0', 'block_11_project_BN/beta:0', 'block_11_project_BN/gamma:0', 'block_11_project_BN/moving_mean:0', 'block_11_project_BN/moving_variance:0', 'block_12_depthwise/depthwise_kernel:0', 'block_12_depthwise_BN/beta:0', 'block_12_depthwise_BN/gamma:0', 'block_12_depthwise_BN/moving_mean:0', 'block_12_depthwise_BN/moving_variance:0', 'block_12_expand/kernel:0', 'block_12_expand_BN/beta:0', 'block_12_expand_BN/gamma:0', 'block_12_expand_BN/moving_mean:0', 'block_12_expand_BN/moving_variance:0', 'block_12_project/kernel:0', 'block_12_project_BN/beta:0', 'block_12_project_BN/gamma:0', 'block_12_project_BN/moving_mean:0', 'block_12_project_BN/moving_variance:0', 'block_13_depthwise/depthwise_kernel:0', 'block_13_depthwise_BN/beta:0', 'block_13_depthwise_BN/gamma:0', 'block_13_depthwise_BN/moving_mean:0', 'block_13_depthwise_BN/moving_variance:0', 'block_13_expand/kernel:0', 'block_13_expand_BN/beta:0', 'block_13_expand_BN/gamma:0', 'block_13_expand_BN/moving_mean:0', 'block_13_expand_BN/moving_variance:0', 'block_13_project/kernel:0', 'block_13_project_BN/beta:0', 'block_13_project_BN/gamma:0', 'block_13_project_BN/moving_mean:0', 'block_13_project_BN/moving_variance:0', 'block_14_depthwise/depthwise_kernel:0', 'block_14_depthwise_BN/beta:0', 'block_14_depthwise_BN/gamma:0', 'block_14_depthwise_BN/moving_mean:0', 'block_14_depthwise_BN/moving_variance:0', 'block_14_expand/kernel:0', 'block_14_expand_BN/beta:0', 'block_14_expand_BN/gamma:0', 'block_14_expand_BN/moving_mean:0', 'block_14_expand_BN/moving_variance:0', 'block_14_project/kernel:0', 'block_14_project_BN/beta:0', 'block_14_project_BN/gamma:0', 'block_14_project_BN/moving_mean:0', 'block_14_project_BN/moving_variance:0', 'block_15_depthwise/depthwise_kernel:0', 'block_15_depthwise_BN/beta:0', 'block_15_depthwise_BN/gamma:0', 'block_15_depthwise_BN/moving_mean:0', 'block_15_depthwise_BN/moving_variance:0', 'block_15_expand/kernel:0', 'block_15_expand_BN/beta:0', 'block_15_expand_BN/gamma:0', 'block_15_expand_BN/moving_mean:0', 'block_15_expand_BN/moving_variance:0', 'block_15_project/kernel:0', 'block_15_project_BN/beta:0', 'block_15_project_BN/gamma:0', 'block_15_project_BN/moving_mean:0', 'block_15_project_BN/moving_variance:0', 'block_16_depthwise/depthwise_kernel:0', 'block_16_depthwise_BN/beta:0', 'block_16_depthwise_BN/gamma:0', 'block_16_depthwise_BN/moving_mean:0', 'block_16_depthwise_BN/moving_variance:0', 'block_16_expand/kernel:0', 'block_16_expand_BN/beta:0', 'block_16_expand_BN/gamma:0', 'block_16_expand_BN/moving_mean:0', 'block_16_expand_BN/moving_variance:0', 'block_16_project/kernel:0', 'block_16_project_BN/beta:0', 'block_16_project_BN/gamma:0', 'block_16_project_BN/moving_mean:0', 'block_16_project_BN/moving_variance:0', 'block_1_depthwise/depthwise_kernel:0', 'block_1_depthwise_BN/beta:0', 'block_1_depthwise_BN/gamma:0', 'block_1_depthwise_BN/moving_mean:0', 'block_1_depthwise_BN/moving_variance:0', 'block_1_expand/kernel:0', 'block_1_expand_BN/beta:0', 'block_1_expand_BN/gamma:0', 'block_1_expand_BN/moving_mean:0', 'block_1_expand_BN/moving_variance:0', 'block_1_project/kernel:0', 'block_1_project_BN/beta:0', 'block_1_project_BN/gamma:0', 'block_1_project_BN/moving_mean:0', 'block_1_project_BN/moving_variance:0', 'block_2_depthwise/depthwise_kernel:0', 'block_2_depthwise_BN/beta:0', 'block_2_depthwise_BN/gamma:0', 'block_2_depthwise_BN/moving_mean:0', 'block_2_depthwise_BN/moving_variance:0', 'block_2_expand/kernel:0', 'block_2_expand_BN/beta:0', 'block_2_expand_BN/gamma:0', 'block_2_expand_BN/moving_mean:0', 'block_2_expand_BN/moving_variance:0', 'block_2_project/kernel:0', 'block_2_project_BN/beta:0', 'block_2_project_BN/gamma:0', 'block_2_project_BN/moving_mean:0', 'block_2_project_BN/moving_variance:0', 'block_3_depthwise/depthwise_kernel:0', 'block_3_depthwise_BN/beta:0', 'block_3_depthwise_BN/gamma:0', 'block_3_depthwise_BN/moving_mean:0', 'block_3_depthwise_BN/moving_variance:0', 'block_3_expand/kernel:0', 'block_3_expand_BN/beta:0', 'block_3_expand_BN/gamma:0', 'block_3_expand_BN/moving_mean:0', 'block_3_expand_BN/moving_variance:0', 'block_3_project/kernel:0', 'block_3_project_BN/beta:0', 'block_3_project_BN/gamma:0', 'block_3_project_BN/moving_mean:0', 'block_3_project_BN/moving_variance:0', 'block_4_depthwise/depthwise_kernel:0', 'block_4_depthwise_BN/beta:0', 'block_4_depthwise_BN/gamma:0', 'block_4_depthwise_BN/moving_mean:0', 'block_4_depthwise_BN/moving_variance:0', 'block_4_expand/kernel:0', 'block_4_expand_BN/beta:0', 'block_4_expand_BN/gamma:0', 'block_4_expand_BN/moving_mean:0', 'block_4_expand_BN/moving_variance:0', 'block_4_project/kernel:0', 'block_4_project_BN/beta:0', 'block_4_project_BN/gamma:0', 'block_4_project_BN/moving_mean:0', 'block_4_project_BN/moving_variance:0', 'block_5_depthwise/depthwise_kernel:0', 'block_5_depthwise_BN/beta:0', 'block_5_depthwise_BN/gamma:0', 'block_5_depthwise_BN/moving_mean:0', 'block_5_depthwise_BN/moving_variance:0', 'block_5_expand/kernel:0', 'block_5_expand_BN/beta:0', 'block_5_expand_BN/gamma:0', 'block_5_expand_BN/moving_mean:0', 'block_5_expand_BN/moving_variance:0', 'block_5_project/kernel:0', 'block_5_project_BN/beta:0', 'block_5_project_BN/gamma:0', 'block_5_project_BN/moving_mean:0', 'block_5_project_BN/moving_variance:0', 'block_6_depthwise/depthwise_kernel:0', 'block_6_depthwise_BN/beta:0', 'block_6_depthwise_BN/gamma:0', 'block_6_depthwise_BN/moving_mean:0', 'block_6_depthwise_BN/moving_variance:0', 'block_6_expand/kernel:0', 'block_6_expand_BN/beta:0', 'block_6_expand_BN/gamma:0', 'block_6_expand_BN/moving_mean:0', 'block_6_expand_BN/moving_variance:0', 'block_6_project/kernel:0', 'block_6_project_BN/beta:0', 'block_6_project_BN/gamma:0', 'block_6_project_BN/moving_mean:0', 'block_6_project_BN/moving_variance:0', 'block_7_depthwise/depthwise_kernel:0', 'block_7_depthwise_BN/beta:0', 'block_7_depthwise_BN/gamma:0', 'block_7_depthwise_BN/moving_mean:0', 'block_7_depthwise_BN/moving_variance:0', 'block_7_expand/kernel:0', 'block_7_expand_BN/beta:0', 'block_7_expand_BN/gamma:0', 'block_7_expand_BN/moving_mean:0', 'block_7_expand_BN/moving_variance:0', 'block_7_project/kernel:0', 'block_7_project_BN/beta:0', 'block_7_project_BN/gamma:0', 'block_7_project_BN/moving_mean:0', 'block_7_project_BN/moving_variance:0', 'block_8_depthwise/depthwise_kernel:0', 'block_8_depthwise_BN/beta:0', 'block_8_depthwise_BN/gamma:0', 'block_8_depthwise_BN/moving_mean:0', 'block_8_depthwise_BN/moving_variance:0', 'block_8_expand/kernel:0', 'block_8_expand_BN/beta:0', 'block_8_expand_BN/gamma:0', 'block_8_expand_BN/moving_mean:0', 'block_8_expand_BN/moving_variance:0', 'block_8_project/kernel:0', 'block_8_project_BN/beta:0', 'block_8_project_BN/gamma:0', 'block_8_project_BN/moving_mean:0', 'block_8_project_BN/moving_variance:0', 'block_9_depthwise/depthwise_kernel:0', 'block_9_depthwise_BN/beta:0', 'block_9_depthwise_BN/gamma:0', 'block_9_depthwise_BN/moving_mean:0', 'block_9_depthwise_BN/moving_variance:0', 'block_9_expand/kernel:0', 'block_9_expand_BN/beta:0', 'block_9_expand_BN/gamma:0', 'block_9_expand_BN/moving_mean:0', 'block_9_expand_BN/moving_variance:0', 'block_9_project/kernel:0', 'block_9_project_BN/beta:0', 'block_9_project_BN/gamma:0', 'block_9_project_BN/moving_mean:0', 'block_9_project_BN/moving_variance:0', 'bn_Conv1/beta:0', 'bn_Conv1/gamma:0', 'bn_Conv1/moving_mean:0', 'bn_Conv1/moving_variance:0', 'expanded_conv_depthwise/depthwise_kernel:0', 'expanded_conv_depthwise_BN/beta:0', 'expanded_conv_depthwise_BN/gamma:0', 'expanded_conv_depthwise_BN/moving_mean:0', 'expanded_conv_depthwise_BN/moving_variance:0', 'expanded_conv_project/kernel:0', 'expanded_conv_project_BN/beta:0', 'expanded_conv_project_BN/gamma:0', 'expanded_conv_project_BN/moving_mean:0', 'expanded_conv_project_BN/moving_variance:0', 'pred/bias:0', 'pred/kernel:0']}, 'save': {'inputs': ['checkpoint_path'], 'outputs': ['checkpoint_path']}, 'train': {'inputs': ['x', 'y'], 'outputs': ['loss']}}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the TensorFlow Lite model\n",
    "interpreter = tf.lite.Interpreter(model_path='/content/drive/MyDrive/model.tflite')\n",
    "\n",
    "signatures = interpreter.get_signature_list()\n",
    "print('Signature:', signatures)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d42AxH2fPDyw"
   },
   "outputs": [],
   "source": [
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input details\n",
    "input_details = interpreter.get_input_details()\n",
    "input_index = input_details[0]['index']\n",
    "\n",
    "# Define new tensor size\n",
    "new_size = [5, 160, 160, 3]  # Example: Changing batch size to 5\n",
    "\n",
    "# Resize the input tensor\n",
    "interpreter.resize_tensor_input(input_index, new_size, strict=False)\n",
    "\n",
    "# Allocate tensors again after resizing\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c83SCD52RV0I",
    "outputId": "f513f9cc-e016-4fd5-99e6-fc7500cc5202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tensor 0:\n",
      "Name: infer_x:0\n",
      "Shape: [  5 160 160   3]\n",
      "Data Type: <class 'numpy.float32'>\n",
      "Output Tensor 0:\n",
      "Name: StatefulPartitionedCall:0\n",
      "Shape: [ 5 10]\n",
      "Data Type: <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "# Get input tensor details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Print input tensor details\n",
    "for i, input_tensor in enumerate(input_details):\n",
    "    print(f\"Input Tensor {i}:\")\n",
    "    print(f\"Name: {input_tensor['name']}\")\n",
    "    print(f\"Shape: {input_tensor['shape']}\")\n",
    "    print(f\"Data Type: {input_tensor['dtype']}\")\n",
    "\n",
    "# Print output tensor details\n",
    "for i, output_tensor in enumerate(output_details):\n",
    "    print(f\"Output Tensor {i}:\")\n",
    "    print(f\"Name: {output_tensor['name']}\")\n",
    "    print(f\"Shape: {output_tensor['shape']}\")\n",
    "    print(f\"Data Type: {output_tensor['dtype']}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 25496,
     "sourceId": 30345,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 25955,
     "sourceId": 30926,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 25958,
     "sourceId": 30929,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 16293,
     "sourceId": 19643,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30684,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
